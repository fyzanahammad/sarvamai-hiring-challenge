{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task : Semantic Chunking of a Youtube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "The objective is to extract high-quality, meaningful (semantic) segments from the specified YouTube video: Watch Video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Suggested workflow:\n",
    "\n",
    "**1. Download Video and Extract Audio:** Download the video and separate the audio component. <br>\n",
    "**2. Transcription of Audio:** Utilize an open-source Speech-to-Text model to transcribe the audio. Provide an explanation of the chosen model and any techniques used to enhance the quality of the transcription. <br>\n",
    "**3. Time-Align Transcript with Audio:** Describe the methodology and steps for aligning the transcript with the audio. <br>\n",
    "**4. Semantic Chunking of Data:** Slice the data into audio-text pairs, using both semantic information from the text and voice activity information from the audio, with each audio-chunk being less than 15s in length. Explain the logic used for semantic chunking and discuss the strengths and weaknesses of your approach.<br>\n",
    "\n",
    "Judgement Criteria:\n",
    "\n",
    "Precision-Oriented Evaluation: The evaluation focuses on precision rather than recall. Higher scores are achieved by reporting fewer but more accurate segments rather than a larger number of segments with inaccuracies. Segment accuracy is determined by:\n",
    "\n",
    "Transcription Quality: Accuracy of the text transcription for each audio chunk.\n",
    "Segment Quality: Semantic richness of the text segments.\n",
    "Timestamp Accuracy: Precision of the start and end times for each segment. Avoid audio cuts at the start or end of a segment.\n",
    "Detailed Explanations: Provide reasoning behind each step in the process.\n",
    "\n",
    "Generalization: Discuss the general applicability of your approach, potential failure modes on different types of videos, and adaptation strategies for other languages.\n",
    "\n",
    "[Bonus-1] Gradio-app Interface: Wrap your code in a gradio-app which takes in youtube link as input and displays the output in a text-box.\n",
    "\n",
    "[Bonus-2] Utilizing Ground-Truth Transcripts: Propose a method to improve the quality of your transcript using a ground-truth transcript provided as a single text string. Explain your hypothesis for this approach. Note that code-snippet isn't required for this question.\n",
    "\n",
    "As an example - for the audio extracted from yt-link, how can we leverage transcript scraped from here, to improve the overall transcription quality of segments?\n",
    "\n",
    "Submission Format:\n",
    "\n",
    "Your submission should be a well-documented Jupyter notebook capable of reproducing your results. The notebook should automatically install all required dependencies and output the results in the specified format.\n",
    "\n",
    "Output Format: Provide the results as a list of dictionaries, each representing a semantic chunk. Each dictionary should include:\n",
    "chunk_id: A unique identifier for the chunk (integer).\n",
    "chunk_length: The duration of the chunk in seconds (float).\n",
    "text: The transcribed text of the chunk (string).\n",
    "start_time: The start time of the chunk within the video (float).\n",
    "end_time: The end time of the chunk within the video (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output_list = [\n",
    "    {\n",
    "        \"chunk_id\": 1,\n",
    "        \"chunk_length\": 14.5,\n",
    "        \"text\": \"Here is an example of a semantic chunk from the video.\",\n",
    "        \"start_time\": 0.0,\n",
    "        \"end_time\": 14.5,\n",
    "    },\n",
    "    # Additional chunks follow...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that your code is clear, well-commented, and easy to follow, with explanations for each major step and decision in the process. The notebook should be able to install all the dependencies automatically and generate the reported output when run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Steps:\n",
    "1. Download Video and Extract Audio\n",
    "2. Transcription of Audio\n",
    "3. Time-Align Transcript with Audio\n",
    "4. Semantic Chunking of Data\n",
    "5. Evaluation and Judgement Criteria\n",
    "6. Generalization\n",
    "7. Gradio App Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Video and Extract Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtube_dl\n",
    "from moviepy.editor import *\n",
    "\n",
    "def download_video_extract_audio(youtube_url, output_audio_file):\n",
    "    # Download video\n",
    "    ydl_opts = {'format': 'bestaudio/best'}\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    # Extract audio\n",
    "    video = VideoFileClip(youtube_url)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(output_audio_file)\n",
    "\n",
    "download_video_extract_audio('https://youtube.com/watch?v=your_video_id', 'output_audio.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarvam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
